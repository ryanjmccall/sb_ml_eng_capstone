{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52d57180",
   "metadata": {},
   "source": [
    "## Machine Learning Engineering Career Track Capstone\n",
    "    \n",
    "### Step 6: Experiment With Various Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180eac98",
   "metadata": {},
   "source": [
    "The purpose of this step is for you to rigorously test how to build the best model for analyzing the patterns found in your dataset. \n",
    "Perform some of the following activities:\n",
    "- Build an automated process to test many modeling techniques and ML algorithms with your data to see which one yields the best results\n",
    "- Define the performance metric(s) best applied to your problem (accuracy, F1, RSME, LOC, etc.)\n",
    "- Test various loss functions across models to see which one yields the best result\n",
    "- Perform tuning of one or more model, across one or multiple hyperparameters\n",
    "- Build a robust cross-validation process for your problem\n",
    "- Ensemble multiple models together, and demonstrate the superior results\n",
    "- Analyze the prediction results to confirm how some of your models ended up properly generalizing or overfitting the data\n",
    "- Present your best model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "85111d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "from random import sample\n",
    "from time import time\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "import librosa\n",
    "from librosa.display import waveplot\n",
    "import moviepy.editor as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, silhouette_score\n",
    "from sklearn.preprocessing import scale, StandardScaler\n",
    "\n",
    "# models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06ae3989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9986,) (1108,) (2610,)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_pickle('data/features/train/labels.pkl')\n",
    "dev_df = pd.read_pickle('data/features/dev/labels.pkl')\n",
    "test_df = pd.read_pickle('data/features/test/labels.pkl')\n",
    "\n",
    "datasets = (train_df, dev_df, test_df)\n",
    "\n",
    "y_train = train_df['emotion_class']\n",
    "y_dev = dev_df['emotion_class']\n",
    "y_test = test_df['emotion_class']\n",
    "print(y_train.shape, y_dev.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9319fb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9986, 160) (1108, 160) (2610, 160)\n"
     ]
    }
   ],
   "source": [
    "def load_feats(stage: str):\n",
    "    outpath = 'data/features/{}/{}.pkl'\n",
    "    feat_fnames = ['mel', 'mfcc', 'chroma']\n",
    "    tmp = [pickle.load(open(outpath.format(stage, fn), 'rb')) for fn in feat_fnames]\n",
    "    return np.hstack(tmp)\n",
    "\n",
    "X_train, X_dev, X_test = load_feats('train'), load_feats('dev'), load_feats('test')\n",
    "print(X_train.shape, X_dev.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4365406b",
   "metadata": {},
   "source": [
    "## Experiment: All data, RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d8712446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       153\n",
      "           1       0.00      0.00      0.00        22\n",
      "           2       0.00      0.00      0.00        40\n",
      "           3       0.00      0.00      0.00       163\n",
      "           4       0.42      1.00      0.60       469\n",
      "           5       0.00      0.00      0.00       111\n",
      "           6       0.00      0.00      0.00       150\n",
      "\n",
      "    accuracy                           0.42      1108\n",
      "   macro avg       0.06      0.14      0.09      1108\n",
      "weighted avg       0.18      0.42      0.25      1108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run PCA to get top features, collect as X_train and get y_train\n",
    "\n",
    "model = RandomForestClassifier(class_weight='balanced', random_state=0, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_dev)\n",
    "print('\\n', classification_report(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "73b7906a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "#     MultinomialNB(),  # ValueError: Negative values in data passed to MultinomialNB (input X)\n",
    "    GaussianNB(),\n",
    "    DecisionTreeClassifier(random_state=0, class_weight='balanced'),\n",
    "    RandomForestClassifier(n_jobs=-1, random_state=0, class_weight='balanced'),\n",
    "    KNeighborsClassifier(n_jobs=-1),\n",
    "    LinearSVC(multi_class='ovr', class_weight='balanced', random_state=0),\n",
    "    # TODO increase max_iter\n",
    "    LogisticRegression(multi_class='multinomial', class_weight='balanced', random_state=0, n_jobs=-1),  \n",
    "    LogisticRegression(multi_class='ovr', class_weight='balanced', random_state=0, n_jobs=-1),   \n",
    "    MLPClassifier(random_state=0),\n",
    "    RidgeClassifier(class_weight='balanced', random_state=0)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2b35f6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB  in  0.03\n",
      "DecisionTreeClassifier  in  2.19\n",
      "RandomForestClassifier  in  2.19\n",
      "KNeighborsClassifier  in  0.32\n",
      "LinearSVC  in  36.18\n",
      "LogisticRegression  in  1.99\n",
      "LogisticRegression  in  4.1\n",
      "MLPClassifier  in  2.51\n",
      "RidgeClassifier  in  0.02\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "predictions = dict()\n",
    "for model in classifiers:\n",
    "    start = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_dev)\n",
    "    elapsed = time.time() - start\n",
    "    name = model.__class__.__name__\n",
    "    predictions[name] = y_pred\n",
    "    print(name, ' in ', round(elapsed, 2),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9409097c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1 weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  F1 weighted\n",
       "0    KNeighborsClassifier        0.273\n",
       "1  DecisionTreeClassifier        0.254\n",
       "2           MLPClassifier        0.254\n",
       "3  RandomForestClassifier        0.252\n",
       "4      LogisticRegression        0.166\n",
       "5         RidgeClassifier        0.115\n",
       "6              GaussianNB        0.072\n",
       "7               LinearSVC        0.040"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = [(name, round(f1_score(y_dev, y_pred, average='weighted'), 3)) for name, y_pred in predictions.items()]\n",
    "tmp.sort(key=lambda x: x[1], reverse=True)\n",
    "pd.DataFrame(tmp, columns=[\"Model\", \"F1 weighted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "faa270e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.04      0.05       153\n",
      "           1       0.02      0.05      0.03        22\n",
      "           2       0.04      0.82      0.08        40\n",
      "           3       0.10      0.02      0.04       163\n",
      "           4       0.45      0.05      0.09       469\n",
      "           5       0.09      0.03      0.04       111\n",
      "           6       0.12      0.07      0.09       150\n",
      "\n",
      "    accuracy                           0.07      1108\n",
      "   macro avg       0.13      0.15      0.06      1108\n",
      "weighted avg       0.25      0.07      0.07      1108\n",
      "\n",
      "DecisionTreeClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.08      0.09       153\n",
      "           1       0.02      0.05      0.03        22\n",
      "           2       0.09      0.07      0.08        40\n",
      "           3       0.17      0.23      0.20       163\n",
      "           4       0.44      0.45      0.45       469\n",
      "           5       0.05      0.03      0.03       111\n",
      "           6       0.13      0.11      0.12       150\n",
      "\n",
      "    accuracy                           0.26      1108\n",
      "   macro avg       0.14      0.15      0.14      1108\n",
      "weighted avg       0.25      0.26      0.25      1108\n",
      "\n",
      "RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       153\n",
      "           1       0.00      0.00      0.00        22\n",
      "           2       0.00      0.00      0.00        40\n",
      "           3       0.00      0.00      0.00       163\n",
      "           4       0.42      1.00      0.60       469\n",
      "           5       0.00      0.00      0.00       111\n",
      "           6       0.00      0.00      0.00       150\n",
      "\n",
      "    accuracy                           0.42      1108\n",
      "   macro avg       0.06      0.14      0.09      1108\n",
      "weighted avg       0.18      0.42      0.25      1108\n",
      "\n",
      "KNeighborsClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.12      0.13       153\n",
      "           1       0.00      0.00      0.00        22\n",
      "           2       0.00      0.00      0.00        40\n",
      "           3       0.16      0.20      0.17       163\n",
      "           4       0.43      0.63      0.51       469\n",
      "           5       0.07      0.02      0.03       111\n",
      "           6       0.16      0.05      0.07       150\n",
      "\n",
      "    accuracy                           0.32      1108\n",
      "   macro avg       0.14      0.14      0.13      1108\n",
      "weighted avg       0.25      0.32      0.27      1108\n",
      "\n",
      "LinearSVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       153\n",
      "           1       0.00      0.00      0.00        22\n",
      "           2       0.00      0.00      0.00        40\n",
      "           3       0.15      1.00      0.26       163\n",
      "           4       0.50      0.00      0.00       469\n",
      "           5       0.00      0.00      0.00       111\n",
      "           6       0.00      0.00      0.00       150\n",
      "\n",
      "    accuracy                           0.15      1108\n",
      "   macro avg       0.09      0.14      0.04      1108\n",
      "weighted avg       0.23      0.15      0.04      1108\n",
      "\n",
      "LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.21      0.18       153\n",
      "           1       0.00      0.05      0.01        22\n",
      "           2       0.04      0.20      0.06        40\n",
      "           3       0.15      0.07      0.10       163\n",
      "           4       0.48      0.15      0.23       469\n",
      "           5       0.13      0.12      0.12       111\n",
      "           6       0.12      0.11      0.12       150\n",
      "\n",
      "    accuracy                           0.14      1108\n",
      "   macro avg       0.15      0.13      0.12      1108\n",
      "weighted avg       0.28      0.14      0.17      1108\n",
      "\n",
      "MLPClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.02      0.03       153\n",
      "           1       0.00      0.00      0.00        22\n",
      "           2       0.00      0.00      0.00        40\n",
      "           3       0.11      0.03      0.05       163\n",
      "           4       0.42      0.90      0.57       469\n",
      "           5       0.00      0.00      0.00       111\n",
      "           6       0.00      0.00      0.00       150\n",
      "\n",
      "    accuracy                           0.39      1108\n",
      "   macro avg       0.09      0.14      0.09      1108\n",
      "weighted avg       0.21      0.39      0.25      1108\n",
      "\n",
      "RidgeClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.16      0.16       153\n",
      "           1       0.01      0.09      0.02        22\n",
      "           2       0.04      0.25      0.07        40\n",
      "           3       0.13      0.06      0.08       163\n",
      "           4       0.38      0.05      0.09       469\n",
      "           5       0.13      0.20      0.16       111\n",
      "           6       0.16      0.18      0.17       150\n",
      "\n",
      "    accuracy                           0.11      1108\n",
      "   macro avg       0.14      0.14      0.11      1108\n",
      "weighted avg       0.24      0.11      0.11      1108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, y_pred in predictions.items():\n",
    "    report = classification_report(y_dev, y_pred)\n",
    "    print(name)\n",
    "    print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f016038",
   "metadata": {},
   "source": [
    "### Optimizing KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b88655",
   "metadata": {},
   "source": [
    "### Optimizing MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654c0725",
   "metadata": {},
   "source": [
    "### Optimizing RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3482ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
